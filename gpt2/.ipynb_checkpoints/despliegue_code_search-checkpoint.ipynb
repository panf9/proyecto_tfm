{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd2af17-96d0-4694-9081-657863dab4ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae96ace-043e-424b-8caf-32a434f07bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from safetensors.torch import load_model\n",
    "\n",
    "# Configuraci贸n\n",
    "MODEL_PATH = \"./modelo\"  # Ruta donde est谩n tus archivos\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Cargar tokenizer y config\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Necesario para GPT-2\n",
    "\n",
    "# Cargar modelo desde safetensors\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    local_files_only=True,\n",
    "    torch_dtype=torch.float16 if DEVICE == \"cuda\" else torch.float32\n",
    ").to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "def comentar_codigo(snippet):\n",
    "    # Plantilla de prompt (ajusta seg煤n tu entrenamiento)\n",
    "    prompt = f\"Comenta este c贸digo Python:\\n```python\\n{snippet}\\n```\\nC贸digo comentado:\\n```python\\n\"\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=300,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decodificar y limpiar la salida\n",
    "    full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    codigo_comentado = full_output.split(\"C贸digo comentado:\")[-1].strip()\n",
    "    \n",
    "    # Eliminar el cierre del code block si existe\n",
    "    return codigo_comentado.replace(\"```\", \"\").strip()\n",
    "\n",
    "# Interfaz mejorada\n",
    "css = \"\"\"\n",
    ".code-output {\n",
    "    font-family: monospace !important;\n",
    "    white-space: pre;\n",
    "}\n",
    "\"\"\"\n",
    "with gr.Blocks(css=css, title=\"Comentador GPT-2\") as demo:\n",
    "    gr.Markdown(\"##  Comentador Autom谩tico de C贸digo (GPT-2)\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        input_code = gr.Code(\n",
    "            label=\"Tu c贸digo\",\n",
    "            language=\"python\",\n",
    "            lines=15,\n",
    "            elem_classes=\"code-output\"\n",
    "        )\n",
    "        output_code = gr.Code(\n",
    "            label=\"C贸digo Comentado\",\n",
    "            language=\"python\",\n",
    "            lines=15,\n",
    "            elem_classes=\"code-output\"\n",
    "        )\n",
    "    \n",
    "    btn = gr.Button(\"Generar Comentarios\", variant=\"primary\")\n",
    "    \n",
    "    # Ejemplos pr谩cticos\n",
    "    examples = [\n",
    "        [\"def factorial(n):\\n    if n == 0:\\n        return 1\\n    return n * factorial(n-1)\"],\n",
    "        [\"class Calculadora:\\n    def __init__(self):\\n        self.resultado = 0\\n\\n    def suma(self, a, b):\\n        return a + b\"],\n",
    "        [\"for i in range(10):\\n    print(f'Valor: {i}')\"]\n",
    "    ]\n",
    "    \n",
    "    gr.Examples(examples=examples, inputs=input_code, label=\"Ejemplos\")\n",
    "    \n",
    "    btn.click(\n",
    "        fn=comentar_codigo,\n",
    "        inputs=input_code,\n",
    "        outputs=output_code\n",
    "    )\n",
    "\n",
    "demo.launch(\n",
    "    server_name=\"0.0.0.0\",\n",
    "    share=False  # True para enlace p煤blico temporal\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
