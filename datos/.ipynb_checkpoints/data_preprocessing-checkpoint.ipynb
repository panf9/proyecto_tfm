{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9bc5b09-c143-412b-8e88-4928c6746802",
   "metadata": {},
   "source": [
    "# Acondicionamiento del DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85221111-fe9f-4979-b28c-67b70d1d080a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Ruta de la carpeta que contiene los archivos\n",
    "folder_path = 'python/python/final/jsonl/train/'\n",
    "\n",
    "# Lista para almacenar los DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Recorrer todos los archivos en la carpeta\n",
    "for i in range(14):\n",
    "    filename = f'python_train_{i}.jsonl.gz'\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Leer cada archivo y agregarlo a la lista\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "        df = pd.read_json(f, lines=True)\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "print(final_df.head())\n",
    "\n",
    "# Opcional: guardar el resultado en CSV o JSON para no tener que repetir el proceso\n",
    "# final_df.to_csv('data_consolidada.csv', index=False)\n",
    "# final_df.to_json('data_consolidada.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6543a77-bf6c-426a-850e-8566ea1da035",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1af5c32-e424-4c16-a59c-a11e906f6e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f33ffd3-2926-499d-b7b9-a82b3188daf7",
   "metadata": {},
   "source": [
    "# ELIMINANDO COMENTARIOS Y DOCSTRING DEL CÓDIGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fea213-f797-49d3-bca1-1cc0decc4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import warnings\n",
    "\n",
    "def limpiar_codigo(codigo):\n",
    "    \"\"\"Elimina docstrings y comentarios manteniendo el código funcional\"\"\"\n",
    "    if not isinstance(codigo, str) or not codigo.strip():\n",
    "        return codigo\n",
    "        \n",
    "    try:\n",
    "        # Intenta eliminar docstrings con AST\n",
    "        try:\n",
    "            tree = ast.parse(codigo)\n",
    "            for node in ast.walk(tree):\n",
    "                if isinstance(node, (ast.FunctionDef, ast.ClassDef, ast.Module)):\n",
    "                    if node.body and isinstance(node.body[0], ast.Expr):\n",
    "                        if isinstance(node.body[0].value, (ast.Str, ast.Constant)):\n",
    "                            node.body = node.body[1:]\n",
    "            codigo = ast.unparse(tree)\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        # Eliminar comentarios de línea (manejo seguro de secuencias de escape)\n",
    "        lineas_limpias = []\n",
    "        for linea in codigo.splitlines():\n",
    "            # Manejo especial para strings que contienen #\n",
    "            in_string = False\n",
    "            char_anterior = None\n",
    "            nueva_linea = []\n",
    "            \n",
    "            for char in linea:\n",
    "                if char in ('\"', \"'\") and char_anterior != '\\\\':\n",
    "                    in_string = not in_string\n",
    "                if not in_string and char == '#':\n",
    "                    break\n",
    "                nueva_linea.append(char)\n",
    "                char_anterior = char\n",
    "                \n",
    "            linea_limpia = ''.join(nueva_linea).rstrip()\n",
    "            if linea_limpia:\n",
    "                lineas_limpias.append(linea_limpia)\n",
    "                \n",
    "        return '\\n'.join(lineas_limpias)\n",
    "        \n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error procesando código: {str(e)}\")\n",
    "        return codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4a6afe-1bed-47a7-8f8b-db3b075179bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas problemáticas antes de procesar\n",
    "mask = df['code'].str.contains(r'print\\s[^(]|\\\\.', regex=True)\n",
    "problematic_rows = df[mask]\n",
    "clean_rows = df[~mask]\n",
    "\n",
    "# Procesar por separado\n",
    "clean_rows['code_clean'] = clean_rows['code'].apply(limpiar_codigo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3716fc36-2cb1-4cfd-ba25-08e89f30021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_rows['code_clean'].iloc[315])\n",
    "print(\"========\")\n",
    "print(clean_rows['code'].iloc[315])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479ba947-7a7c-4cb6-b806-54c1d033fe5f",
   "metadata": {},
   "source": [
    "## Guardamos el dataset de modo que pueda ser usado por la librería transformers de hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b72059-d557-4b3a-b282-33d0118eeadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_rows.to_json('dataset_train_filtrado.jsonl', orient='records', lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4489c725-bf64-4121-8b83-cfc76ab0b0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
